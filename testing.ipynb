{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in=open(\"word_bucket.pickle\",\"rb\")\n",
    "word_bucket=pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "model_pred=tf.keras.models.load_model(\"DL_sentimentanalysis_new.h5\")\n",
    "output=[\"Negative\",\"Positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=set(stopwords.words('english'))\n",
    "def remove_punctuation(string):\n",
    "    punctuations='''!()[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    for chars in string:\n",
    "        if chars in punctuations:\n",
    "            string=string.replace(chars,\"\")\n",
    "    return(string)\n",
    "\n",
    "def remove_alpha_numeric(string):\n",
    "    line=list()\n",
    "    for words in string.split(\" \"):\n",
    "        if words.isalpha() == True and words not in stopwords:\n",
    "            line.append(words)\n",
    "    return(line)\n",
    "\n",
    "def lower_case(string):\n",
    "    S_list=list()\n",
    "    for s in string:\n",
    "        S_list.append(s.lower())     \n",
    "    return(S_list)\n",
    "\n",
    "def cleaning_text(data):\n",
    "    cleaned_data=list()\n",
    "    for d in data:\n",
    "        d1=remove_punctuation(d)\n",
    "        d1=remove_alpha_numeric(d1)\n",
    "        d1=lower_case(d1)\n",
    "        cleaned_data.append(d1)\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_set(data,vocab):\n",
    "    dataset=[]\n",
    "    for desc in data:\n",
    "        vector=[]\n",
    "        for d in vocab:\n",
    "            if d in desc:\n",
    "                vector.append(1)\n",
    "            else:\n",
    "                vector.append(0)\n",
    "        dataset.append(vector)\n",
    "    return(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Type 'quit' to quit : \")\n",
    "while True:    \n",
    "    string=input(\"Enter a statement \")\n",
    "    if string == 'quit':\n",
    "        break\n",
    "    string=cleaning_text([string])\n",
    "    test=preparing_set(string,word_bucket)\n",
    "    test=np.array(test).reshape(-1,len(word_bucket))\n",
    "    prediction=model_pred.predict_proba(test)\n",
    "    if prediction[0][np.argmax(prediction)]>=0.60:\n",
    "        print(output[np.argmax(prediction)])\n",
    "    else:\n",
    "        print(\"Neural\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
